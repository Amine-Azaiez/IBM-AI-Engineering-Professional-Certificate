{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m827.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.2 pyarrow-18.1.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 12:20:59.852537: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-26 12:20:59.855174: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 12:20:59.859158: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 12:20:59.871637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735215659.890774     110 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735215659.896381     110 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-26 12:20:59.914985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 12:21:03.145140: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 13.5014\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.2436\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 998ms/step - loss: 0.1833\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.2187\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1499\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1928\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 995ms/step - loss: 0.2584\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1444\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1621\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.2053\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1070\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: 0.1108\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1222\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1577\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0771\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0866\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1000\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0938\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0547\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f44de35dfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 308ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 7.1188\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 1.3961\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.8900\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.3579\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.2356\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0819\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0542\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0344\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0265\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0298\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0234\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0228\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0182\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0163\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0188\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0158\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0127\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0177\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0132\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0126\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 301ms/step - loss: 0.0048\n",
      "Test loss: 0.003796360921114683\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 602ms/step - loss: 0.0185\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 600ms/step - loss: 0.0318\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 585ms/step - loss: 0.0254\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 575ms/step - loss: 0.0307\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 581ms/step - loss: 0.0232\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 573ms/step - loss: 0.0268\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0186\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 575ms/step - loss: 0.0226\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 573ms/step - loss: 0.0213\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 577ms/step - loss: 0.0225\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 575ms/step - loss: 0.0166\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 579ms/step - loss: 0.0281\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 583ms/step - loss: 0.0187\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0272\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 574ms/step - loss: 0.0143\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 592ms/step - loss: 0.0156\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 596ms/step - loss: 0.0264\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 598ms/step - loss: 0.0125\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 594ms/step - loss: 0.0080\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 592ms/step - loss: 0.0114\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 297ms/step - loss: 5.7261e-04\n",
      "Test loss with batch size 16: 0.0006162490462884307\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0066\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0049\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0047\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0034\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0030\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0034\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0034\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0040\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0034\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0036\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 296ms/step - loss: 5.0555e-04\n",
      "Test loss with batch size 64: 0.0005335196619853377\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 0.1337\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0275\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0130\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0140\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0066\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0039\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0042\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0042\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0039\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0026\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0037\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0028\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0029\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0022\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0040\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0034\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0018\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0033\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0019\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 307ms/step - loss: 0.0025\n",
      "Test loss with tanh activation: 0.0015790192410349846\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
